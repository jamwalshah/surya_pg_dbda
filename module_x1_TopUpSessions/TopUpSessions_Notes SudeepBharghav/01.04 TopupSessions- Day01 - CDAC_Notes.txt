Three types of variations
1. trend- with the change in population
2. seasonal- repeat itself after a certain number of time stamps eg every Nov, sales are more
3. random variations - without any known reason - not considered in time series modelling

4. cyclical - repeats a very long period of time - not considered in time series modelling

Data cleaning and validation
1. Find the location of missing values and replace them with a certain value
a. Repalce the missing values with the average of all others - overall average remains unchanged
b. Replace the missing value with the value for the previous time stamp or next time stamp, Aug 2017 is missing. put the value of July, 2017 or Sept 2017 in its place
c. Replace the missing value with the average of pervious and next time stamp. Aug 2017 is missing. put the average of the value of July, 2017 and Sept 2017 in its place. Also called as linear interpolation. Good when there is no seasonal variation.
d. Replace the missing value with the value of same month in the previous or next year. Aug 2017 is missing. We can use values from Aug 2016 and Aug 2018

2. Check for extreme values or the outliers
plot the box plot for all the available values

# Commands to be run in Python

import numpy as np

import pandas as pd

import matplotlib

from matplotlib import pyplot as plt

import statsmodels

import statsmodels.api as sm

from statsmodels.tsa.seasonal import seasonal_decompose

from sklearn.metrics import mean_squared_error

from math import sqrt

df = pd.read_excel('CDAC_DataBook.xlsx', sheet_name = 'birth')

df.shape
Out[11]: (168, 1)

168/12
Out[12]: 14.0

df.head()
Out[13]: 
   BirthRate
0     26.663
1     23.598
2     26.931
3     24.740
4     25.806

df.BirthRate.plot()

df_train = df.iloc[:144]   # split for creating the model

df_train.shape
Out[16]: (144, 1)

df_test = df.iloc[144:]	   # for finding out the error

df_test.shape
Out[18]: (24, 1)

decomp = statsmodels.tsa.seasonal.seasonal_decompose(df.BirthRate, period=12)

decomp.plot()   # decompose to visualize different sources of variations

# Techniques for making predictions

# naive method - whatever happened on the last time stamp would continue into the future

df_arr = np.asarray(df_train.BirthRate)   # convert the train data to an array
y_hat = df_test.copy()   # create a copy for the test data
y_hat['naive'] = df_arr[len(df_arr)-1] 	# create column for naive technique and fill it with last value
rms_naive = sqrt(mean_squared_error(df_test.BirthRate,y_hat.naive))	# calculate rmse

plt.figure(figsize=(12,8))
plt.plot(df_train.index, df_train.BirthRate, label='Train')
plt.plot(df_test.index, df_test.BirthRate, label='Test')
plt.plot(y_hat.index,y_hat.naive, label='Forecast')
plt.legend()


# Simple Average technique

y_hat_avg = df_test.copy()
y_hat_avg['SimpleAvg'] = df_train['BirthRate'].mean()
rms_SimpleAvg = sqrt(mean_squared_error(df_test.BirthRate,y_hat_avg.SimpleAvg))

# Moving Average technique
y_hat_avg['MovingAvg'] = df_train['BirthRate'].rolling(12).mean().iloc[-1]
rms_MovingAvg = sqrt(mean_squared_error(df_test.BirthRate,y_hat_avg.MovingAvg))


# WeightedMovingAverage

# last month (latest value) gets the weightage of 12 and the earliest value or the first manth gets the weightage of 1

values = df_train['BirthRate'].iloc[-12:]

#### prog to calculated weighted moving average

wt_sum = 0
denom = 0
for ctr in range(len(values)):
    wt_sum = wt_sum+ values.iloc[ctr]*(ctr+1)
    denom = denom + ctr+1
wt_avg = wt_sum/denom

#####

y_hat_avg['WtMovAvg'] = wt_avg

rms_MovingAvg = sqrt(mean_squared_error(df_test.BirthRate,y_hat_avg.WtMovAvg))

# Simple Exponential Smoothing

from statsmodels.tsa.api import ExponentialSmoothing, SimpleExpSmoothing, Holt
mod1 = SimpleExpSmoothing(np.asarray(df_train.BirthRate)).fit(smoothing_level=0.8)
y_hat_avg['SES'] = mod1.forecast(len(df_test))
rms_MovingAvg = sqrt(mean_squared_error(df_test.BirthRate,y_hat_avg.SES))

# Holt's linear trend method

mod2 = Holt(np.asarray(df_train.BirthRate)).fit(smoothing_level=0.75)
y_hat_avg['HoltLinear'] = mod2.forecast(len(df_test))
rms_MovingAvg = sqrt(mean_squared_error(df_test.BirthRate,y_hat_avg.HoltLinear))

# Holt-Winter's method

mod3 = ExponentialSmoothing(np.asarray(df_train.BirthRate), seasonal_periods=12).fit()
y_hat_avg['HoltWinter'] = mod3.forecast(len(df_test))
rms_MovingAvg = sqrt(mean_squared_error(df_test.BirthRate,y_hat_avg.HoltWinter))













