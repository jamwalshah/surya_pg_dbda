# Day 15 - BigDataTechnologies

## Apache Spark

1. Spark is ...
    - Not a modified version of Hadoop
    - A low latency cluster computing system
    - Separate, fast, MapReduce-like engine
      - In-memory data storage for very fast iterative queries
      - General execution graphs and powerful optimizations
      - 40x to 100x faster than Hadoop
      - 100x faster than MapReduce for iterative algorithms
    - Compatible with Hadoop's storage APIs
      - can read/write to any Hadoop-supported system, including HDFS, HBase, SequenceFiles, etc.
        ![Spark-read-write-drawing](../content_BigDataTechnologies/Spark-read-write-drawing.png)
2. Apache Spark is an open-source distributed data processing engine for big data analytics
3. utilizes in-memory caching, and optimized query execution for faster analytics against data of any size, isn't tied to Hadoop's MapReduce two-stage paradigm
4. provides development APIs in Java, Scala, Python and R
5. supports code reusability across multiple nodes for batch processing, interactive querying, real-time analytics, machine learning and graph processing
6. initially started by Matei Zaharia at UC Berkeley's AMPLab in 2009, open-sourced in 2010, donated to Apache Software Foundation in 2013
7. 

## Data Sharing in Hadoop MapReduce vs Apache Spark

## Apache Spark Architecture

## Data Flow in Spark

## Apache Spark APIs

### PySpark

### SparkR

### RDDs

#### Lazy Evaluation

### DataFrame

### Data Set

### Actions and Transformations

## Apache Spark Programming Model

## Fault Tolerance in Apache Spark

## Apache Spark Hands-on (Transactions dataset)

### Starting PySpark

### Find the Category of Transactions with Highest Net Value

## reduceByKey() & sortBy()
