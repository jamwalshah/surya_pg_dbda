from pyspark.sql.types import StructType, StringType, IntegerType, DoubleType, LongType

schema9 = StructType().add("exchange_name",StringType(),True).add("stock_id",StringType(),True).add("stock_dt",StringType(),True).add("open",DoubleType(),True).add("high",DoubleType(),True).add("low",DoubleType(),True).add("close",DoubleType(),True).add("volume",LongType(),True).add("adj_close",DoubleType(),True)      

df_with_schema = spark.read.format("csv").option("header","False").schema(schema9).load("hdfs://nameservice1/user/bigdatalab456422/training/NYSE.csv")

df_with_schema.printSchema()

df_with_schema.show()

df_with_schema.registerTempTable("nyse")

df_StockVol = spark.sql("select stock_id, sum(volume) from nyse group by stock_id")

df_StockVol.rdd.getNumPartitions()

df_new = df_StockVol.repartition(1)
df_new = df_StockVol.coalesce(1)

df_new.write.csv("hdfs://nameservice1/user/bigdatalab456422/training/spark4")



------------------------------------------------------------------------------
schema2 = StructType().add("Year",StringType(),True).add("Quarter",StringType(),True).add("ARPS",DoubleType(),True).add("Booked_seats",IntegerType(),True) 


df_with_schema2 = spark.read.format("csv").option("header", "True").schema(schema2).load("hdfs://nameservice1/user/bigdatalab456422/training/airlines.csv")

df_with_schema2.registerTempTable("airlines")

YrWiseRev = spark.sql("select year, round(sum(arps*booked_seats)/1000000,2) as total_in_mill from airlines group by year order by total_in_mill desc")

YrWisePsx = spark.sql("select year, sum(booked_seats) as total_psx from airlines group by year order by total_psx desc")
