# PG-DBDA : Practical Machine Learning 

=================================================
## Day 1: Introduction to Machine Learning
=================================================
Date: 03/07/2023
Topics:
------------------
	-Machine learning
	-Algorithm types of Machine learnin
	-Uses of Machine learning 
	-Evaluating ML techniques 			
	-Supervised and Unsupervised Learning 
	-AI vs ML Vs DL
	-Introduction to ML Libraries
	
	
	
	
Learning: acqusition of knowledge using experience

ML : A computer program  is said to learn from experience E 
with respect to some class of task T and performance measure P,
if it performance at taks T, as measured by P, improves with experience E


Learning:  Improving with experience at some task.
----------

Machine Learning: Data + Algorithms + Computing	
------------------

Machine Learning: Algorithms + Mathematics + Computer Science
----------------

Mathematics: Applied Maths + Statistics + Psycology + Applications	
-------------

How does Machine Learning work :
--------------------------------

## Homework:
-------------

1. Prepare ML application for Interview preparation.
## Homework:
-------------

	Q1. Unique ML example in real life.
	Q2. Study Numpy Library.
	
# Generate matrix:
Ex 1
###    1  2  3  4  5
###    6  7  8  9 10
###   11 12 13 14 15
###   16 17 18 19 20
###   21 22 23 24 25
###   26 27 28 29 30

# Acces 
        11 12
        16 17
    
# Acces  
         2
           8
            14
              20

# Acces        
                4  5



               24 25
               29 30
			   
# Reference:
-------------
## Reference docs (https://docs.scipy.org/doc/numpy/reference/routines.linalg.html)

	# Determinant
	# Trace
	# Singular Vector Decomposition
	# Eigenvalues
	# Matrix Norm
	# Inverse

## Interview Questions:
---------------------
	1. What is meant by “learning” in the context of machine learning?
	
	
	2. What is Machine Learning? Give example.
	3. List out the types of machine learning with an example.
	4. What are the differences between supervised and unsupervised learning?
	5. What is meant by supervised classification?
	6. Explain supervised learning with an example.
	7. What do you mean by reinforcement learning?
	8. Challenges in Machine Learning.
	
=================================================
## Day 2: Machine Learning with Python Libraries
=================================================
Date: 14/07/2022
Topics:
------------------
	-Python Libraries
	-Numpy
	-Pandas
	-Matplotlib
	-Seaborn

## Homework:
-------------
=================================================
## Day 3: Data Pre-processing
=================================================
Date: 05/07/2022
Topics:
------------------
	-Data
	-Types of Attributes
	-Preprocessing
	-Transformations
	-Measures
	-Visualization


Data Quality Challenges:
	-Noise and Outliers
	-Missing values
	-Duplicate data

Data Cleaning:
	-Noise: eg: Distortion on phone
		-Noise refers to random modification of original values
		
	-Outliers: eg: Data entry or instrument error
		-considerably different than most of the other data objects
		
	-Missing values: no values available or not applicable
		-Information not collected
		
	-Duplicate data: Repetitions or different stage formats
		-Repeated entry for the data
		
Handling Techniques:

	-By deleting the particular record
	-By substituting the mean value

## Homework:
-------------

## Interview Questions:
--------------------
	1.What is Data?
	2. What is information?
	3. What is Raw data?
	4. What is Dataset?
	5. Why do we need pre-processing of data?
	6. What are major tasks in data pre-processing?
	7. What is noisy data?
	8. How to handle noisy data?
	9. What is missing value?
	10. How to handle missing data?
	11. List the tools for data pre-processing
	12. What do you mean by data cleaning?
	13: What is Data Preprocessing? What preprocessing steps do you know?   
	14: What is the difference between Data Processing and Data Mining?  Related To: Data Mining
	15: What is Data Binning?  
	16: What's the difference between Feature Engineering vs. Feature Selection? 

=================================================
## Day 4: Exploratory Data Analysis
=================================================
Date: 06/07/2023
Topics:
------------------
	-Knowledge Extraction
	-EDA
	-Modelling
	

Steps in Knowledge discovery:
------------------------------

1. GoaL :
2. Data Selection, acquisition, integration
3. Exploratory Data Analysis
4. Modelling
5. Testing and verification
6. Interpretation 
7. Conclusion



Challenges:
------------
1. Large data
2. High dimensionality
3. Overfitting
4. Changing data, missing data and noise 
5. Domain knowledge
6. Understanding the patterns generated by model

EDA : Exploratory Data Analysis
--------------------------------

Categorical data Summary statistics:
-------------------------------------
	-Frequency
	-Mode
	-Quantiles


Continuous summary statistics:
--------------------------------
	-Mean
	-Median
	-Quantiles
	
	-Range 
	-Variance
	-Intequartile ranges



Ex: data[0,1,2,3,4,22,5,6,7,8,20000]

Entropy:
----------
0: very predictive
1: very random


Distance and Similarity:
------------------------
	-Rank correlation
	
	-Distance /Similarity between 2 types of data
		-Manhattan distance
		-Euclidian distance
		-Jaccard coefficient
		-Edit distance

Visualization:
-----------------

=================================================
## Day 5: Regression
================================================
Date: 07/07/2022
Topics:
------------------
	-Linear Regression 
	-Multiple Linear Regression
	-Polynomial Regression 

Machine Learning Modelling:
----------------------------

	-Regression
	-Classification
	
Regression:
-used to study the relationship between two variables
-Dependent variable (y)
-Independent variable (x)
-x: coutinuos or categorical input values
-y: continuos values

TSS:Total sum of squares

TSS= sum[(Actual(y)-Mean(y))]^2

RSS: Residual sum of squares

RSS = sum[(Actual(y)- Predicted(y))]^2

ESS:Explained sum of squares

ESS =sum[(Predicted(y)-Mean(y))]^2

OLS : Ordinary Least Square:
	-designed to fita line through scatter plot data points in such a way that
	the sum of the squared derviations of the points from the line is minimumized.

R^2: Coefficient of determination 
	-Value= 0 to 100	
	-Coefficient of determination  is a measure which indicates the percentage
	of the variation in the dependent variable is due to the independent variable.
	-Measure of goodness of the model


Steps in Regression model implementation:
------------------------------------------

	1.Importing the libraries and dataset
	2.Splitting the dataset into the Training set and Test set
	3.Preprocessing if required
	4.Fitting Simple Linear Regression to the Training set
	5.Predicting the Test set results
	6.Visualizing the Test set results

### Steps for Regression Model:
-----------------------------
	1.Importing the libraries
	2.Importing dataset
		-head,shape,describe
		-X,Y
	3.Identify Independent and Dependent variables
		-Assign values to X,y
	-----MLR----------
	#Pre-processing
		Encoder
		scaling
	-----------------------
	4.Splitting the dataset into Training and Testing
		-Split train & Test
		-Model building-SLR/MLR/PLR
	5.Predicting the Training Results
		-testing data
	6.Visualising the Training and Testing Results
		-X_test,y_pred
	7.Metrics
		-intercept, coeff
		-MSE,R2,Accuracy


Simple Linear Regression
============================
1.Importing the libraries
--------------------------

import numpy as np
import matplotlib.pyplot as plt
import pandas as pd


2.Importing Dataset
----------------------
dataset = pd.read_csv('Data.csv')


​3.Identify Independent and Dependent variables
----------------------------------------------
X = dataset.iloc[:, :-1].values
y = dataset.iloc[:, -1].values


4.Splitting the dataset into the Training set and Test set
--------------------------------------------------------------
from sklearn.model_selection import train_test_split
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 1/3, random_state = 0)
Training the Simple Linear Regression model on the Training set


5.Apply Linear Regression()
---------------------------
from sklearn.linear_model import LinearRegression
regressor = LinearRegression()
regressor.fit(X_train, y_train)


6.Predicting the Training set results
---------------------------------------
y_pred = regressor.predict(X_test)


7.Visualising the Training set results
---------------------------------------
#Training dataset:
------------------
plt.scatter(X_train, y_train, color = 'red')
plt.plot(X_train, regressor.predict(X_train), color = 'blue')

#Testing dataset:
-----------------
plt.scatter(X_test, y_test, color = 'red')
plt.plot(X_train, regressor.predict(X_train), color = 'blue')


8.Meteris
-------------
	-reg coefficient
	-intercept
	-MSE
	-Model Summary
	-R2

	
## HomeWork:
-----------
Build the Regression Model for Linear, MultiLinear and Polynomial Regression
Use dataset:
--------------
	a.	Day5data3 and 
	b.	Ecommerce Customer


=================================================
## Day 6: Types of Regression 
================================================
Date: 08/07/2022
Topics:
------------------
	-Ridge Regression 
	-Lasso Regression 
	-ElasticNet Regression 
	-Logistic Regression 
	
## HomeWork:
-----------
Classification using Logistic Model

## Interview Questions:
--------------------

1. What are the different types of regression.
2. Is regression a supervised learning? Why?
3. Explain the ordinary least squares method for regression.
4. What are linear, multinomial and polynomial regressions.
5. If model used for regression is y = a + b(x − 1)2;
is it a multinomial regression? If not, what type of regression is it?
6. What does the line of regression tell you?

=================================================
## Day 6: Types of Regression & Classification
================================================
Date: 10/07/2023
Topics:
------------------
	-Ridge Regression 
	-Lasso Regression 
	-ElasticNet Regression 
	-Logistic Regression 




Ridge Regression:
	-make use of L2 Regularization
	-perform feature weight updates as aloss function has an additional square term

Lasso Regression:
	-make use of L1 Regularization
	-perform feature weight updates as aloss function has an additional square term
	containing L1 norm of the weights vector


## HomeWork:
-----------
Classification using Logistic Model


=================================================
Day 8: Classification
================================================
Date: 11/07/2023
Topics:
------------------

	-Logistic Regression
	-Classification
	
Join Zoom Meeting:
------------------

Meeting ID: 871 5180 5574
Passcode: 392492


Classification: 
----------------
A machine learning task that deals with identifying 
the class to which an instance belongs.


Evaluation metric: Accuracy, Confusion matrix


Types of classification:
------------------------
	-Binary classification:
		-classification problem has only two possible outcomes, then
		it is called as Binary classification.
		
		-eg: YES/NO, MALE/FEMALE, SPAM/NOTSPAM
	
	-Multi-class classification:
		-classification problem has more than two outcomes, then 
		it is called as Multi-class classification.
		
			-eg: classification of disorders, classification of size of T-shirt,
			classification of types of crops, classification of music
			
Learners:
------------
	-Lazy learner: 
		-stores training dataset and wait until test dataset is provided.
		-eg:K-NN algorithm
	
	-Eagaer Learner:
		-devlope classification model based on training dataset before 
		receiving the test dataset
		-Decision Trees, Naive Bayes, ANN

Classification Techniques:
--------------------------
	-Base classifier
		-Decision Tree
		-Rule base Method
		-Nearest Neighbour
		-Naive Bayes
		-Support Vector Machine (SVM)
		-Neural Network
		
	Ensemble classifier:
		-Boosting
		-Bagging
		-Random Forest
		

Conditional Probablity:
------------------------
P(A/B)= P(A n B)/P(B)

np.concatenate((y_pred.reshape(len(y_pred),1), y_test.reshape(len(y_test),1)),1)



# Assigning features and label variables
# First Feature
weather=['Sunny','Sunny','Overcast','Rainy','Rainy','Rainy','Overcast','Sunny','Sunny',
'Rainy','Sunny','Overcast','Overcast','Rainy']
# Second Feature
temp=['Hot','Hot','Hot','Mild','Cool','Cool','Cool','Mild','Cool','Mild','Mild','Mild','Hot','Mild']

# Label or target varible
play=['No','No','Yes','Yes','Yes','No','Yes','No','Yes','Yes','Yes','Yes','Yes','No']


=================================================
Day 9: Classification Algorithm
================================================
Date: 12/07/2023
Topics:
------------------
	-Classification Algorithm
	-KNN
	-Naive Bayes
	
 
Meeting ID: 871 5180 5574
Passcode: 392492

KNN Algorithm:

	-powerful algorithm
	-used for pattern recognition
	-works on the principle of distance(similarity measure)
	-stores near nearest neighbours data points
	-non-parametric algorithm
	-lazy learner algorithm
	-also called as instance based algorithm


-Non-parametric:
		-algorithms do not make particular assumptions about the kind of mapping function.
		-algorithm do not accept a specific form of the mapping functions
		-they have freedom to choose any functional form from the training dataset.
		
		
#Interview Questions:
----------------------
1. What is K NEarest Neighbour Algorithms?
2. How does the KNN Algorithm work?
3. Why KNN is a non-Parametric Algorithm ?
4. Does the need for feature Scaling exit in KNN ?
5. Can the KNN algorith be used for REgression problems ?
6. Why is the KNN Algorithm considered as a "Lazy Learner" ?
7. How the categorica variables be handled in the KNN algorithm ?
8. How can the Bias-Variance Tradeoff be related to the KNN Algorithm ?
9. What is the role of k value in the KNN algorithm ?
10. How to choose the optimal value of k in the KNN ?

=================================================
Day 10: Classification Algorithm
================================================
Date: 12/07/2023
# Topics:
------------------
	-Classification Algorithm
	-Naive Bayes
	-Decision Tree
	
# Probability Language:
-----------------------
Event: is a result that an outcome may occur

Probability: is a value between 1 and 0 that an event will occur

certain: means an event will occur and has a probability of 1

uncertain: means an event won't occur and has a probability of 0

Even chance: means there is a 50:50 chance of the event occuring


# Conditional Probability:
-------------------------
P(A/B) : Probability of A given B

P(AnB) : Probability of A and b intersection

P(B) : Probability of B


#Interview Questions
-----------------------

1. What is Naive Bayes?
2. How does Naive Bayes work?
3. What are the applications of Naive Bayes?
4. What is the formula given by Bayes theorem?
5. What is posterior probability and prior probability in Naïve Bayes?
6. Is Naive Bayes is a discriminative classifier or generative classifier?
7. What is the formula given by Bayes theorem?
8. What is posterior probability and prior probability in Naïve Bayes?
9. Define Bayes theorem in terms of prior, evidence and likelihood.
10. While calculating the probability of a given situation, what error can we run into in Naïve Bayes and how can we solve it?
11. What is the Bernoulli distribution in Naïve Bayes?
12. How does Naïve Bayes treat numerical and categorical values?
13. What is the best dataset scenario for the Naïve Bayes Classifier?
14. What’s the difference between Generative Classifiers and Discriminative Classifiers?